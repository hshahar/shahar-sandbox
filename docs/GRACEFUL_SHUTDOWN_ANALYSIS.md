# Graceful Shutdown Analysis - SHA Kubernetes Blog Platform

## ×‘×“×™×§×ª ×¢×§×¨×•× ×•×ª ×›×™×‘×•×™ ××œ×’× ×˜×™ (Graceful Shutdown)

×ª××¨×™×š ×¢×“×›×•×Ÿ ××—×¨×•×Ÿ: 2025-11-09
××˜×¨×”: ×•×™×“×•× ×™×™×©×•× ×¢×§×¨×•× ×•×ª Graceful Shutdown ×œ×¢××™×“×•×ª ×‘×–××Ÿ Scale-Down

---

## ğŸ“‹ ×¡×™×›×•× ×××¦××™× - ×¢×“×›×•×Ÿ ×¡×•×¤×™

| ×¢×§×¨×•×Ÿ | ×¡×˜×˜×•×¡ | ×”×¢×¨×•×ª |
|-------|--------|-------|
| 1. ×˜×™×¤×•×œ ×‘-SIGTERM ×‘××¤×œ×™×§×¦×™×” | âœ… ××™×•×©× | Signal handlers + shutdown middleware |
| 2. preStop Hook | âœ… ××™×•×©× | Backend: 10s, Frontend: 5s + nginx quit |
| 3. terminationGracePeriodSeconds | âœ… ××•×’×“×¨ | Backend: 60s, Frontend: 30s |
| 4. Readiness Probe ××—××™×¨×” | âœ… ××™×•×©× | /ready endpoint ××—×–×™×¨ 503 ×‘×–××Ÿ shutdown |
| 5. PodDisruptionBudget (PDB) | âœ… ××™×•×©× | minAvailable: 1 ×œ×©× ×™ ×”×©×™×¨×•×ª×™× |
| 6. HPA Scale-Down ×—×›× | âœ… ××™×•×©× | stabilizationWindow: 600s, selectPolicy: Min |
| 7. Connection Draining ×‘-Ingress | âœ… ××™×•×©× | Timeout annotations: 120s |

**×¦×™×•×Ÿ ×›×•×œ×œ: 7/7 (100%)**

---

## ğŸ‰ ×©×™×¤×•×¨×™× ×©×”×•×¡×¤×•

### 1. âœ… ×˜×™×¤×•×œ ×‘-SIGTERM ×‘××¤×œ×™×§×¦×™×”

**××” ×”×•×¡×£ ×‘-app/backend/main.py:**

```python
import signal
import asyncio

# Global shutdown state
is_shutting_down = False
shutdown_event = asyncio.Event()

# Signal handlers
def handle_sigterm(signum, frame):
    global is_shutting_down
    print(f"Received signal {signum}, starting graceful shutdown...")
    is_shutting_down = True

signal.signal(signal.SIGTERM, handle_sigterm)
signal.signal(signal.SIGINT, handle_sigterm)

# Shutdown middleware - reject new requests during shutdown
@app.middleware("http")
async def shutdown_middleware(request: Request, call_next):
    global is_shutting_down
    if is_shutting_down and request.url.path not in ["/health", "/ready", "/metrics"]:
        return Response(
            content="Service is shutting down",
            status_code=503,
            headers={"Retry-After": "30"}
        )
    response = await call_next(request)
    return response

# Shutdown event handler
@app.on_event("shutdown")
async def shutdown():
    global is_shutting_down
    is_shutting_down = True
    await asyncio.sleep(2)  # Wait for in-flight requests
    engine.dispose()  # Close DB connections
```

**×™×ª×¨×•× ×•×ª:**
- Pod ××¤×¡×™×§ ×œ×§×‘×œ ×‘×§×©×•×ª ×—×“×©×•×ª ××™×“ ×œ××—×¨ SIGTERM
- ×‘×§×©×•×ª ×¤×¢×™×œ×•×ª ×××©×™×›×•×ª ×œ×”×ª×‘×¦×¢ (×¢×“ 2 ×©× ×™×•×ª)
- ×—×™×‘×•×¨×™ DB × ×¡×’×¨×™× ×‘×¦×•×¨×” × ×›×•× ×”
- ×œ×§×•×—×•×ª ××§×‘×œ×™× 503 ×¢× Retry-After header

---

### 2. âœ… preStop Hook

**××” ×”×•×¡×£ ×‘-backend-deployment.yaml:**

```yaml
lifecycle:
  preStop:
    exec:
      command:
      - /bin/sh
      - -c
      - |
        # Sleep to allow load balancer to remove pod from endpoints
        sleep {{ .Values.backend.preStopSleepSeconds | default 10 }}
```

**××” ×”×•×¡×£ ×‘-frontend-deployment.yaml:**

```yaml
lifecycle:
  preStop:
    exec:
      command:
      - /bin/sh
      - -c
      - |
        # Sleep to allow load balancer to remove pod from endpoints
        sleep {{ .Values.frontend.preStopSleepSeconds | default 5 }}
        # Gracefully stop nginx
        /usr/sbin/nginx -s quit
```

**×™×ª×¨×•× ×•×ª:**
- Sleep × ×•×ª×Ÿ ×–××Ÿ ×œ-Endpoints controller ×œ×”×¡×™×¨ ××ª ×”-Pod ××”-Service
- nginx quit ×¢×•×¦×¨ ××ª nginx ×‘×¦×•×¨×” × ×›×•× ×” (××¡×™×™× ×‘×§×©×•×ª ×¤×¢×™×œ×•×ª)
- ××•× ×¢ race condition ×‘×™×Ÿ ×”×¡×¨×” ×-endpoints ×œ-SIGTERM

---

### 3. âœ… terminationGracePeriodSeconds

**××” ×”×•×¡×£ ×‘-backend-deployment.yaml:**

```yaml
terminationGracePeriodSeconds: {{ .Values.backend.terminationGracePeriodSeconds | default 60 }}
```

**××” ×”×•×¡×£ ×‘-frontend-deployment.yaml:**

```yaml
terminationGracePeriodSeconds: {{ .Values.frontend.terminationGracePeriodSeconds | default 30 }}
```

**××” ×”×•×¡×£ ×‘-values.yaml:**

```yaml
frontend:
  terminationGracePeriodSeconds: 30
  preStopSleepSeconds: 5

backend:
  terminationGracePeriodSeconds: 60
  preStopSleepSeconds: 10
```

**×™×ª×¨×•× ×•×ª:**
- Backend ××§×‘×œ 60 ×©× ×™×•×ª (preStop: 10s + app shutdown: 2s + buffer: 48s)
- Frontend ××§×‘×œ 30 ×©× ×™×•×ª (preStop: 5s + nginx shutdown + buffer)
- ××•× ×¢ SIGKILL ××•×§×“× ×©×œ ×ª×”×œ×™×›×™×

---

### 4. âœ… Readiness Probe ××—××™×¨×”

**××” ×”×•×¡×£ ×‘-app/backend/main.py:**

```python
@app.get("/ready")
async def readiness_check():
    """Readiness probe - checks if app is ready to serve traffic"""
    global is_shutting_down

    # Return not ready during shutdown
    if is_shutting_down:
        raise HTTPException(status_code=503, detail="Shutting down")

    try:
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        return {"status": "ready"}
    except Exception:
        raise HTTPException(status_code=503, detail="Not ready")
```

**×©×™× ×•×™ ×‘-backend-deployment.yaml:**

```yaml
readinessProbe:
  httpGet:
    path: /ready  # Changed from /health to /ready
    port: http
  initialDelaySeconds: 15
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
```

**×™×ª×¨×•× ×•×ª:**
- Pod ××•×¡×¨ ×-Service endpoints ××™×“ ×›×©-is_shutting_down=True
- K8s ××¤×¡×™×§ ×œ×©×œ×•×— ×‘×§×©×•×ª ×—×“×©×•×ª ×œ-Pod
- ×¢×•×‘×“ ×‘×©×™×ª×•×£ ×¢× preStop hook ×œ××¢×‘×¨ ×—×œ×§

---

### 5. âœ… PodDisruptionBudget (PDB)

**×§×‘×¦×™× ×—×“×©×™× ×©× ×•×¦×¨×•:**

**backend-pdb.yaml:**
```yaml
{{- if and .Values.backend.enabled .Values.backend.pdb.enabled }}
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: {{ include "microservices-app.fullname" . }}-backend-pdb
spec:
  {{- if .Values.backend.pdb.minAvailable }}
  minAvailable: {{ .Values.backend.pdb.minAvailable }}
  {{- else if .Values.backend.pdb.maxUnavailable }}
  maxUnavailable: {{ .Values.backend.pdb.maxUnavailable }}
  {{- else }}
  minAvailable: 1
  {{- end }}
  selector:
    matchLabels:
      app: backend
{{- end }}
```

**frontend-pdb.yaml:**
```yaml
{{- if and .Values.frontend.enabled .Values.frontend.pdb.enabled }}
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: {{ include "microservices-app.fullname" . }}-frontend-pdb
spec:
  minAvailable: {{ .Values.frontend.pdb.minAvailable | default 1 }}
  selector:
    matchLabels:
      app: frontend
{{- end }}
```

**×”×•×¡×£ ×œ-values.yaml:**
```yaml
frontend:
  pdb:
    enabled: true
    minAvailable: 1

backend:
  pdb:
    enabled: true
    minAvailable: 1
```

**×™×ª×¨×•× ×•×ª:**
- ××•× ×¢ ×™×¨×™×“×” ×©×œ ×™×•×ª×¨ ×-Pod ××—×“ ×‘×•-×–×× ×™×ª
- ×©×•××¨ ×–××™× ×•×ª ×©×™×¨×•×ª ×‘×–××Ÿ node drain ××• cluster upgrades
- ×¢×•×‘×“ ×¢× HPA ×œ×× ×™×¢×ª scale-down ××”×™×¨ ××“×™

---

### 6. âœ… HPA Scale-Down ×—×›×

**××” ×©×•× ×” ×‘-backend-hpa.yaml:**

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: {{ .Values.backend.autoscaling.scaleDown.stabilizationWindowSeconds | default 600 }}
    selectPolicy: Min  # NEW: Choose the policy that scales down least
    policies:
    - type: Percent
      value: {{ .Values.backend.autoscaling.scaleDown.percentValue | default 50 }}
      periodSeconds: {{ .Values.backend.autoscaling.scaleDown.periodSeconds | default 60 }}
    - type: Pods
      value: {{ .Values.backend.autoscaling.scaleDown.podsValue | default 1 }}  # NEW
      periodSeconds: {{ .Values.backend.autoscaling.scaleDown.periodSeconds | default 60 }}
```

**×™×ª×¨×•× ×•×ª:**
- stabilizationWindow: 600s - ×××ª×™×Ÿ 10 ×“×§×•×ª ×œ×¤× ×™ scale-down
- selectPolicy: Min - ×‘×•×—×¨ ×‘××“×™× ×™×•×ª ×©-scales down ×‘×–×”×™×¨×•×ª ×‘×™×•×ª×¨
- ××•× ×¢ thrashing (scale up/down ××”×™×¨)
- × ×•×ª×Ÿ ×–××Ÿ ×œ-PDB ×•-graceful shutdown ×œ×¢×‘×•×“

---

### 7. âœ… Connection Draining ×‘-Ingress

**××” ×”×•×¡×£ ×œ×›×œ ×§×‘×¦×™ values (dev/staging/prod):**

```yaml
ingress:
  annotations:
    # Connection draining for graceful shutdown
    nginx.ingress.kubernetes.io/proxy-send-timeout: "120"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "120"
    nginx.ingress.kubernetes.io/upstream-keepalive-timeout: "120"
```

**×™×ª×¨×•× ×•×ª:**
- Nginx Ingress ×××ª×™×Ÿ ×¢×“ 120 ×©× ×™×•×ª ×œ×¡×™×•× ×‘×§×©×•×ª
- ×ª×•×× ×œ-terminationGracePeriodSeconds ×©×œ ×”×¤×•×“×™×
- ××•× ×¢ 502/504 errors ×‘××”×œ×š rolling updates

---

## ğŸ”„ ×ª×¨×©×™× ×–×¨×™××” - Graceful Shutdown

```
1. kubectl delete pod/rollout/scale-down
   â†“
2. Pod status â†’ Terminating
   â†“
3. [PARALLEL - ×§×•×¨×” ×‘××§×‘×™×œ]
   â”œâ”€â†’ Readiness probe fails (/ready returns 503)
   â”‚   â””â”€â†’ Pod removed from Service endpoints (10s)
   â”‚
   â””â”€â†’ preStop hook executes
       â””â”€â†’ Sleep 10s (backend) / 5s (frontend)
   â†“
4. After preStop: SIGTERM sent to container
   â†“
5. Signal handler: is_shutting_down = True
   â†“
6. Shutdown middleware: Reject new requests (503)
   â†“
7. In-flight requests complete (up to 2s)
   â†“
8. DB connections close (engine.dispose())
   â†“
9. Container exits gracefully
   â†“
10. If still running after terminationGracePeriodSeconds:
    â””â”€â†’ SIGKILL (force kill)
```

---

## ğŸ“ ×¡×™×›×•×

×›×œ 7 ×¢×§×¨×•× ×•×ª ×”×›×™×‘×•×™ ×”××œ×’× ×˜×™ ××™×•×©××™× ×›×¢×ª ×‘×¤×¨×•×™×§×˜:

1. **SIGTERM handlers** - ×‘-FastAPI ×¢× middleware ×•-event handlers
2. **preStop hooks** - ×‘×©× ×™ ×”-Deployments ×¢× sleep ××ª××™×
3. **terminationGracePeriodSeconds** - 60s ×œbackend, 30s ×œfrontend
4. **Readiness probe** - endpoint ××ª×•×—×›× ×©×‘×•×“×§ shutdown state
5. **PodDisruptionBudget** - minAvailable=1 ×œ×× ×™×¢×ª downtime
6. **HPA behavior** - stabilization window ××¨×•×š + selectPolicy: Min
7. **Ingress annotations** - connection draining ×©×œ 120s

×”×¤×¨×•×™×§×˜ ×›×¢×ª ××•×›×Ÿ ×œ-production ×¢× zero-downtime deployments! ğŸš€
